{"config":{"indexing":"full","lang":["pt"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Amora Data Build Tool (ADBT) \u00b6 Amora Data Build Tool enables analysts and engineers to transform data on the data warehouse (BigQuery) by writing Amora Models that describe the data schema using Python's PEP484 - Type Hints and select statements with SQLAlchemy . Amora is able to transform Python code into SQL data transformation jobs that run inside the warehouse. When should I use? \u00b6 Use case 1 Use case 2 Use case 3 Installation \u00b6 Pypi \u00b6 pip install amora Setup Big Query permissions \u00b6 In order to use Amora with BigQuery, you'll need to setup a keyfile . Go to the BigQuery credential wizard . Ensure that the right project is selected in the header bar. Generate credentials with the following options: Which API are you using? BigQuery API What data will you be accessing? Application data (you'll be creating a service account) Are you planning to use this API with App Engine or Compute Engine? No Service account name: amora-user Role : BigQuery Job User & BigQuery User Key type : JSON Download the JSON file and save it in an easy-to-remember spot, with a clear filename (e.g. ~/.bq-service-accounts/amora-user-credentials.json ) Set the environment variable GOOGLE_APPLICATION_CREDENTIALS to the path of the JSON file that contains your service account key. You can add export GOOGLE_APPLICATION_CREDENTIALS=~/.bq-service-accounts/amora-user-credentials.json to your shell initialization script ( .zshrc for zsh, .bash_profile for bash, ...) Required roles: BigQuery Data Editor ( roles/bigquery.dataEditor ) BigQuery User ( roles/bigquery.user ) How to use? \u00b6 Amora is packed with a compiler and a runner . The compiler (CLI amora compile ) compiles Amora's python models into SQL statements which can be executed against the configured data warehouse using amora materialize . The animation above displays an user inside an Amora Project using Amora's CLI amora compile to compile model files into SQL statements and creating the corresponding views/tables into the Data Warehouse (BigQuery) using amora materialize . If you want to know more about the features, check the features page","title":"Amora"},{"location":"#amora-data-build-tool-adbt","text":"Amora Data Build Tool enables analysts and engineers to transform data on the data warehouse (BigQuery) by writing Amora Models that describe the data schema using Python's PEP484 - Type Hints and select statements with SQLAlchemy . Amora is able to transform Python code into SQL data transformation jobs that run inside the warehouse.","title":"Amora Data Build Tool (ADBT)"},{"location":"#when-should-i-use","text":"Use case 1 Use case 2 Use case 3","title":"When should I use?"},{"location":"#installation","text":"","title":"Installation"},{"location":"#pypi","text":"pip install amora","title":"Pypi"},{"location":"#setup-big-query-permissions","text":"In order to use Amora with BigQuery, you'll need to setup a keyfile . Go to the BigQuery credential wizard . Ensure that the right project is selected in the header bar. Generate credentials with the following options: Which API are you using? BigQuery API What data will you be accessing? Application data (you'll be creating a service account) Are you planning to use this API with App Engine or Compute Engine? No Service account name: amora-user Role : BigQuery Job User & BigQuery User Key type : JSON Download the JSON file and save it in an easy-to-remember spot, with a clear filename (e.g. ~/.bq-service-accounts/amora-user-credentials.json ) Set the environment variable GOOGLE_APPLICATION_CREDENTIALS to the path of the JSON file that contains your service account key. You can add export GOOGLE_APPLICATION_CREDENTIALS=~/.bq-service-accounts/amora-user-credentials.json to your shell initialization script ( .zshrc for zsh, .bash_profile for bash, ...) Required roles: BigQuery Data Editor ( roles/bigquery.dataEditor ) BigQuery User ( roles/bigquery.user )","title":"Setup Big Query permissions"},{"location":"#how-to-use","text":"Amora is packed with a compiler and a runner . The compiler (CLI amora compile ) compiles Amora's python models into SQL statements which can be executed against the configured data warehouse using amora materialize . The animation above displays an user inside an Amora Project using Amora's CLI amora compile to compile model files into SQL statements and creating the corresponding views/tables into the Data Warehouse (BigQuery) using amora materialize . If you want to know more about the features, check the features page","title":"How to use?"},{"location":"cli/","text":"CLI \u00b6 Usage: amora [OPTIONS] COMMAND [ARGS]... Amora Data Build Tool enables engineers to transform data in their warehouses by defining schemas and writing select statements with SQLAlchemy. Amora handles turning these select statements into tables and views Options: --install-completion Install completion for the current shell. --show-completion Show completion for the current shell, to copy it or customize the installation. --help Show this message and exit. Commands: compile Generates executable SQL from model files. materialize Executes the compiled SQL against the current target... models test Runs tests on data in deployed models. amora compile \u00b6 Generates executable SQL from model files. Compiled SQL files are written to the ./target directory. Source code in amora/cli.py @app . command () def compile ( models : Optional [ Models ] = models_option , target : Optional [ str ] = target_option , ) -> None : \"\"\" Generates executable SQL from model files. Compiled SQL files are written to the `./target` directory. \"\"\" for model , model_file_path in list_models (): if models and model_file_path . stem not in models : continue source_sql_statement = model . source () if source_sql_statement is None : typer . echo ( f \"\u23ed Skipping compilation of model ` { model_file_path } `\" ) continue target_file_path = model . target_path ( model_file_path ) typer . echo ( f \"\ud83c\udfd7 Compiling model ` { model_file_path } ` -> ` { target_file_path } `\" ) content = compile_statement ( source_sql_statement ) target_file_path . parent . mkdir ( parents = True , exist_ok = True ) target_file_path . write_text ( content ) amora materialize \u00b6 Executes the compiled SQL against the current target database. Source code in amora/cli.py @app . command () def materialize ( models : Optional [ Models ] = models_option , target : str = target_option , draw_dag : bool = typer . Option ( False , \"--draw-dag\" ), ) -> None : \"\"\" Executes the compiled SQL against the current target database. \"\"\" model_to_task = {} for target_file_path in list_target_files (): if models and target_file_path . stem not in models : continue task = materialization . Task . for_target ( target_file_path ) model_to_task [ task . model . unique_name ] = task dag = materialization . DependencyDAG . from_tasks ( tasks = model_to_task . values ()) if draw_dag : dag . draw () for model in dag : try : task = model_to_task [ model ] except KeyError : typer . echo ( f \"\u26a0\ufe0f Skipping ` { model } `\" ) continue else : table = materialization . materialize ( sql = task . sql_stmt , model = task . model ) if table is None : continue typer . echo ( f \"\u2705 Created ` { model } ` as ` { table . full_table_id } `\" ) typer . echo ( f \" Rows: { table . num_rows } \" ) typer . echo ( f \" Bytes: { table . num_bytes } \" ) amora test \u00b6 Runs tests on data in deployed models. Run this after amora materialize to ensure that the date state is up-to-date. Source code in amora/cli.py @app . command () def test ( models : Optional [ Models ] = models_option , ) -> None : \"\"\" Runs tests on data in deployed models. Run this after `amora materialize` to ensure that the date state is up-to-date. \"\"\" return_code = pytest . main ([ \"-n\" , \"auto\" , \"--verbose\" ]) raise typer . Exit ( return_code ) amora models list \u00b6 List the models in your project as a human readable table or as a JSON serialized document amora models list You can also use the option --with-total-bytes to use BigQuery query dry run feature to gather model total bytes information amora models list --with-total-bytes Source code in amora/cli.py @models . command ( name = \"list\" ) def models_list ( format : str = typer . Option ( \"table\" , help = \"Output format. Options: json,table\" , ), with_total_bytes : bool = typer . Option ( False , help = \"Uses BigQuery query dry run feature \" \"to gather model total bytes information\" , ), ) -> None : \"\"\" List the models in your project as a human readable table or as a JSON serialized document ```shell amora models list ``` You can also use the option `--with-total-bytes` to use BigQuery query dry run feature to gather model total bytes information ```shell amora models list --with-total-bytes ``` \"\"\" @dataclass class ResultItem : model : Model dry_run_result : Optional [ DryRunResult ] = None def as_dict ( self ): return { \"depends_on\" : self . depends_on , \"has_source\" : self . has_source , \"materialization_type\" : self . materialization_type , \"model_name\" : self . model_name , \"referenced_tables\" : self . referenced_tables , \"total_bytes\" : self . total_bytes , } @property def model_name ( self ): return self . model . __name__ @property def has_source ( self ): return self . model . source () is not None @property def depends_on ( self ) -> List [ str ]: return sorted ( [ dependency . __name__ for dependency in self . model . dependencies () ] ) @property def total_bytes ( self ) -> Optional [ int ]: if self . dry_run_result : return self . dry_run_result . total_bytes return None @property def referenced_tables ( self ) -> List [ str ]: if self . dry_run_result : return self . dry_run_result . referenced_tables return [] @property def materialization_type ( self ) -> Optional [ str ]: if self . has_source : return self . model . __model_config__ . materialized . value else : return None results = [] for model , model_file_path in list_models (): if with_total_bytes : result_item = ResultItem ( model = model , dry_run_result = dry_run ( model )) else : result_item = ResultItem ( model = model , dry_run_result = None ) results . append ( result_item ) if format == \"table\" : table = Table ( show_header = True , header_style = \"bold\" , show_lines = True , width = settings . CLI_CONSOLE_MAX_WIDTH , row_styles = [ \"none\" , \"dim\" ], ) table . add_column ( \"Model name\" , style = \"green bold\" , no_wrap = True ) table . add_column ( \"Total bytes\" , no_wrap = True ) table . add_column ( \"Referenced tables\" ) table . add_column ( \"Depends on\" ) table . add_column ( \"Has source?\" , no_wrap = True , justify = \"center\" ) table . add_column ( \"Materialization\" , no_wrap = True ) for result in results : table . add_row ( result . model_name , f \" { result . total_bytes or '-' } \" , Text ( \" \\n \" . join ( result . referenced_tables ) or \"-\" , overflow = \"fold\" ), Text ( \" \\n \" . join ( result . depends_on ) or \"-\" , overflow = \"fold\" ), \"\ud83d\udfe2\" if result . has_source else \"\ud83d\udd34\" , result . materialization_type or \"-\" , ) console = Console ( width = settings . CLI_CONSOLE_MAX_WIDTH ) console . print ( table ) elif format == \"json\" : output = { \"models\" : [ result . as_dict () for result in results ]} typer . echo ( json . dumps ( output )) If a machine readable format is required, the --format json option can be used as followed: $ amora models list --format json { \"models\" : [ { \"depends_on\" : [ \"Health\" ], \"has_source\" : true , \"materialization_type\" : \"table\" , \"model_name\" : \"Steps\" , \"referenced_tables\" : [], \"total_bytes\" : null }, { \"depends_on\" : [ \"HeartRate\" ], \"has_source\" : true , \"materialization_type\" : \"table\" , \"model_name\" : \"HeartRateAgg\" , \"referenced_tables\" : [], \"total_bytes\" : null }, { \"depends_on\" : [], \"has_source\" : false , \"materialization_type\" : null , \"model_name\" : \"Health\" , \"referenced_tables\" : [], \"total_bytes\" : null }, { \"depends_on\" : [ \"Health\" ], \"has_source\" : true , \"materialization_type\" : \"table\" , \"model_name\" : \"HeartRate\" , \"referenced_tables\" : [], \"total_bytes\" : null }, { \"depends_on\" : [ \"Steps\" ], \"has_source\" : true , \"materialization_type\" : \"table\" , \"model_name\" : \"StepsAgg\" , \"referenced_tables\" : [], \"total_bytes\" : null } ] } amora models import \u00b6 Generates a new amora model file from an existing table/view amora models import --table-reference my_gcp_project.my_dataset.my_table my_gcp_project/my_dataset/my_table Source code in amora/cli.py @models . command ( name = \"import\" ) def models_import ( table_reference : str = typer . Option ( ... , \"--table-reference\" , help = \"BigQuery unique table identifier. \" \"E.g.: project-id.dataset-id.table-id\" , ), model_file_path : str = typer . Argument ( None , help = \"Canonical name of python module for the generated AmoraModel. \" \"A good pattern would be to use an unique \" \"and deterministic identifier, like: `project_id.dataset_id.table_id`\" , ), overwrite : bool = typer . Option ( False , help = \"Overwrite the output file if one already exists\" ), ): \"\"\" Generates a new amora model file from an existing table/view ```shell amora models import --table-reference my_gcp_project.my_dataset.my_table my_gcp_project/my_dataset/my_table ``` \"\"\" env = Environment ( loader = PackageLoader ( \"amora\" ), autoescape = select_autoescape () ) template = env . get_template ( \"new-model.py.jinja2\" ) project , dataset , table = table_reference . split ( \".\" ) model_name = \"\" . join (( part . title () for part in table . split ( \"_\" ))) destination_file_path = Path ( settings . MODELS_PATH ) . joinpath ( ( model_file_path or model_name . replace ( \".\" , \"/\" )) + \".py\" ) if destination_file_path . exists () and not overwrite : typer . echo ( f \"` { destination_file_path } ` already exists. \" f \"Pass `--overwrite` to overwrite file.\" , err = True , ) raise typer . Exit ( 1 ) model_source_code = template . render ( BIGQUERY_TYPES_TO_PYTHON_TYPES = BIGQUERY_TYPES_TO_PYTHON_TYPES , dataset = dataset , dataset_id = f \" { project } . { dataset } \" , model_name = model_name , project = project , schema = get_schema ( table_reference ), table = table , ) destination_file_path . parent . mkdir ( parents = True , exist_ok = True ) destination_file_path . write_text ( model_source_code ) typer . secho ( f \"\ud83c\udf89 Amora Model ` { model_name } ` (` { table_reference } `) imported!\" , fg = typer . colors . GREEN , bold = True , ) typer . secho ( f \"Current File Path: ` { destination_file_path . as_posix () } `\" )","title":"CLI"},{"location":"cli/#cli","text":"Usage: amora [OPTIONS] COMMAND [ARGS]... Amora Data Build Tool enables engineers to transform data in their warehouses by defining schemas and writing select statements with SQLAlchemy. Amora handles turning these select statements into tables and views Options: --install-completion Install completion for the current shell. --show-completion Show completion for the current shell, to copy it or customize the installation. --help Show this message and exit. Commands: compile Generates executable SQL from model files. materialize Executes the compiled SQL against the current target... models test Runs tests on data in deployed models.","title":"CLI"},{"location":"cli/#amora-compile","text":"Generates executable SQL from model files. Compiled SQL files are written to the ./target directory. Source code in amora/cli.py @app . command () def compile ( models : Optional [ Models ] = models_option , target : Optional [ str ] = target_option , ) -> None : \"\"\" Generates executable SQL from model files. Compiled SQL files are written to the `./target` directory. \"\"\" for model , model_file_path in list_models (): if models and model_file_path . stem not in models : continue source_sql_statement = model . source () if source_sql_statement is None : typer . echo ( f \"\u23ed Skipping compilation of model ` { model_file_path } `\" ) continue target_file_path = model . target_path ( model_file_path ) typer . echo ( f \"\ud83c\udfd7 Compiling model ` { model_file_path } ` -> ` { target_file_path } `\" ) content = compile_statement ( source_sql_statement ) target_file_path . parent . mkdir ( parents = True , exist_ok = True ) target_file_path . write_text ( content )","title":"amora compile"},{"location":"cli/#amora-materialize","text":"Executes the compiled SQL against the current target database. Source code in amora/cli.py @app . command () def materialize ( models : Optional [ Models ] = models_option , target : str = target_option , draw_dag : bool = typer . Option ( False , \"--draw-dag\" ), ) -> None : \"\"\" Executes the compiled SQL against the current target database. \"\"\" model_to_task = {} for target_file_path in list_target_files (): if models and target_file_path . stem not in models : continue task = materialization . Task . for_target ( target_file_path ) model_to_task [ task . model . unique_name ] = task dag = materialization . DependencyDAG . from_tasks ( tasks = model_to_task . values ()) if draw_dag : dag . draw () for model in dag : try : task = model_to_task [ model ] except KeyError : typer . echo ( f \"\u26a0\ufe0f Skipping ` { model } `\" ) continue else : table = materialization . materialize ( sql = task . sql_stmt , model = task . model ) if table is None : continue typer . echo ( f \"\u2705 Created ` { model } ` as ` { table . full_table_id } `\" ) typer . echo ( f \" Rows: { table . num_rows } \" ) typer . echo ( f \" Bytes: { table . num_bytes } \" )","title":"amora materialize"},{"location":"cli/#amora-test","text":"Runs tests on data in deployed models. Run this after amora materialize to ensure that the date state is up-to-date. Source code in amora/cli.py @app . command () def test ( models : Optional [ Models ] = models_option , ) -> None : \"\"\" Runs tests on data in deployed models. Run this after `amora materialize` to ensure that the date state is up-to-date. \"\"\" return_code = pytest . main ([ \"-n\" , \"auto\" , \"--verbose\" ]) raise typer . Exit ( return_code )","title":"amora test"},{"location":"cli/#amora-models-list","text":"List the models in your project as a human readable table or as a JSON serialized document amora models list You can also use the option --with-total-bytes to use BigQuery query dry run feature to gather model total bytes information amora models list --with-total-bytes Source code in amora/cli.py @models . command ( name = \"list\" ) def models_list ( format : str = typer . Option ( \"table\" , help = \"Output format. Options: json,table\" , ), with_total_bytes : bool = typer . Option ( False , help = \"Uses BigQuery query dry run feature \" \"to gather model total bytes information\" , ), ) -> None : \"\"\" List the models in your project as a human readable table or as a JSON serialized document ```shell amora models list ``` You can also use the option `--with-total-bytes` to use BigQuery query dry run feature to gather model total bytes information ```shell amora models list --with-total-bytes ``` \"\"\" @dataclass class ResultItem : model : Model dry_run_result : Optional [ DryRunResult ] = None def as_dict ( self ): return { \"depends_on\" : self . depends_on , \"has_source\" : self . has_source , \"materialization_type\" : self . materialization_type , \"model_name\" : self . model_name , \"referenced_tables\" : self . referenced_tables , \"total_bytes\" : self . total_bytes , } @property def model_name ( self ): return self . model . __name__ @property def has_source ( self ): return self . model . source () is not None @property def depends_on ( self ) -> List [ str ]: return sorted ( [ dependency . __name__ for dependency in self . model . dependencies () ] ) @property def total_bytes ( self ) -> Optional [ int ]: if self . dry_run_result : return self . dry_run_result . total_bytes return None @property def referenced_tables ( self ) -> List [ str ]: if self . dry_run_result : return self . dry_run_result . referenced_tables return [] @property def materialization_type ( self ) -> Optional [ str ]: if self . has_source : return self . model . __model_config__ . materialized . value else : return None results = [] for model , model_file_path in list_models (): if with_total_bytes : result_item = ResultItem ( model = model , dry_run_result = dry_run ( model )) else : result_item = ResultItem ( model = model , dry_run_result = None ) results . append ( result_item ) if format == \"table\" : table = Table ( show_header = True , header_style = \"bold\" , show_lines = True , width = settings . CLI_CONSOLE_MAX_WIDTH , row_styles = [ \"none\" , \"dim\" ], ) table . add_column ( \"Model name\" , style = \"green bold\" , no_wrap = True ) table . add_column ( \"Total bytes\" , no_wrap = True ) table . add_column ( \"Referenced tables\" ) table . add_column ( \"Depends on\" ) table . add_column ( \"Has source?\" , no_wrap = True , justify = \"center\" ) table . add_column ( \"Materialization\" , no_wrap = True ) for result in results : table . add_row ( result . model_name , f \" { result . total_bytes or '-' } \" , Text ( \" \\n \" . join ( result . referenced_tables ) or \"-\" , overflow = \"fold\" ), Text ( \" \\n \" . join ( result . depends_on ) or \"-\" , overflow = \"fold\" ), \"\ud83d\udfe2\" if result . has_source else \"\ud83d\udd34\" , result . materialization_type or \"-\" , ) console = Console ( width = settings . CLI_CONSOLE_MAX_WIDTH ) console . print ( table ) elif format == \"json\" : output = { \"models\" : [ result . as_dict () for result in results ]} typer . echo ( json . dumps ( output )) If a machine readable format is required, the --format json option can be used as followed: $ amora models list --format json { \"models\" : [ { \"depends_on\" : [ \"Health\" ], \"has_source\" : true , \"materialization_type\" : \"table\" , \"model_name\" : \"Steps\" , \"referenced_tables\" : [], \"total_bytes\" : null }, { \"depends_on\" : [ \"HeartRate\" ], \"has_source\" : true , \"materialization_type\" : \"table\" , \"model_name\" : \"HeartRateAgg\" , \"referenced_tables\" : [], \"total_bytes\" : null }, { \"depends_on\" : [], \"has_source\" : false , \"materialization_type\" : null , \"model_name\" : \"Health\" , \"referenced_tables\" : [], \"total_bytes\" : null }, { \"depends_on\" : [ \"Health\" ], \"has_source\" : true , \"materialization_type\" : \"table\" , \"model_name\" : \"HeartRate\" , \"referenced_tables\" : [], \"total_bytes\" : null }, { \"depends_on\" : [ \"Steps\" ], \"has_source\" : true , \"materialization_type\" : \"table\" , \"model_name\" : \"StepsAgg\" , \"referenced_tables\" : [], \"total_bytes\" : null } ] }","title":"amora models list"},{"location":"cli/#amora-models-import","text":"Generates a new amora model file from an existing table/view amora models import --table-reference my_gcp_project.my_dataset.my_table my_gcp_project/my_dataset/my_table Source code in amora/cli.py @models . command ( name = \"import\" ) def models_import ( table_reference : str = typer . Option ( ... , \"--table-reference\" , help = \"BigQuery unique table identifier. \" \"E.g.: project-id.dataset-id.table-id\" , ), model_file_path : str = typer . Argument ( None , help = \"Canonical name of python module for the generated AmoraModel. \" \"A good pattern would be to use an unique \" \"and deterministic identifier, like: `project_id.dataset_id.table_id`\" , ), overwrite : bool = typer . Option ( False , help = \"Overwrite the output file if one already exists\" ), ): \"\"\" Generates a new amora model file from an existing table/view ```shell amora models import --table-reference my_gcp_project.my_dataset.my_table my_gcp_project/my_dataset/my_table ``` \"\"\" env = Environment ( loader = PackageLoader ( \"amora\" ), autoescape = select_autoescape () ) template = env . get_template ( \"new-model.py.jinja2\" ) project , dataset , table = table_reference . split ( \".\" ) model_name = \"\" . join (( part . title () for part in table . split ( \"_\" ))) destination_file_path = Path ( settings . MODELS_PATH ) . joinpath ( ( model_file_path or model_name . replace ( \".\" , \"/\" )) + \".py\" ) if destination_file_path . exists () and not overwrite : typer . echo ( f \"` { destination_file_path } ` already exists. \" f \"Pass `--overwrite` to overwrite file.\" , err = True , ) raise typer . Exit ( 1 ) model_source_code = template . render ( BIGQUERY_TYPES_TO_PYTHON_TYPES = BIGQUERY_TYPES_TO_PYTHON_TYPES , dataset = dataset , dataset_id = f \" { project } . { dataset } \" , model_name = model_name , project = project , schema = get_schema ( table_reference ), table = table , ) destination_file_path . parent . mkdir ( parents = True , exist_ok = True ) destination_file_path . write_text ( model_source_code ) typer . secho ( f \"\ud83c\udf89 Amora Model ` { model_name } ` (` { table_reference } `) imported!\" , fg = typer . colors . GREEN , bold = True , ) typer . secho ( f \"Current File Path: ` { destination_file_path . as_posix () } `\" )","title":"amora models import"},{"location":"examples/","text":"Examples \u00b6 Amora demo project: amora-project","title":"Examples"},{"location":"examples/#examples","text":"Amora demo project: amora-project","title":"Examples"},{"location":"features/","text":"Features \u00b6","title":"Features"},{"location":"features/#features","text":"","title":"Features"},{"location":"models/","text":"Amora Model \u00b6 An Amora Model is a subclass of amora.models.AmoraModel . A way of expressing a data schema , the data materialization and an optional transformation statement. AmoraModel is built on top of SQLModel . Data schema \u00b6 from datetime import datetime from amora.models import AmoraModel , ModelConfig , MaterializationTypes from sqlmodel import Field class Health ( AmoraModel , table = True ): __model_config__ = ModelConfig ( materialized = MaterializationTypes . table , description = \"Health data exported by the Apple Health App\" , ) id : int = Field ( primary_key = True ) type : str sourceName : str sourceVersion : str unit : str creationDate : datetime startDate : datetime endDate : datetime value : float device : str Model Configuration \u00b6 Model configuration metadata Attributes: Name Type Description materialized amora.models.MaterializationTypes The materialization configuration: view , table , ephemeral . Default: view partition_by Optional[PartitionConfig] BigQuery supports the use of a partition by clause to easily partition a table by a column or expression. This option can help decrease latency and cost when querying large tables. cluster_by List[str] BigQuery tables can be clustered to colocate related data. Expects a column of a list of columns. labels Dict[str,str] A dict of labels that can be used as the resource selection description int A string description of the model, used for documentation Transformation \u00b6 Data transformation is defined at the model source() -> Compilable classmethod. Called when amora compile is executed, Amora will build this model in your data warehouse by wrapping it in a create view as or create table as statement. Return None for defining models for tables/views that already exist on the data warehouse and shouldn't be managed by Amora. Return a Compilable , which is a sqlalchemy select statement, in order to compile the model with the given statement :return: Source code in amora/models.py @classmethod def source ( cls ) -> Optional [ Compilable ]: \"\"\" Called when `amora compile` is executed, Amora will build this model in your data warehouse by wrapping it in a `create view as` or `create table as` statement. Return `None` for defining models for tables/views that already exist on the data warehouse and shouldn't be managed by Amora. Return a `Compilable`, which is a sqlalchemy select statement, in order to compile the model with the given statement :return: \"\"\" return None Dependencies \u00b6 A list of Amora Models that the current model depends on Source models \u00b6 Tables/views that already exist on the Data Warehouse and shouldn't be managed by Amora. from datetime import datetime from amora.models import AmoraModel , ModelConfig , MaterializationTypes from sqlmodel import Field class Health ( AmoraModel , table = True ): __model_config__ = ModelConfig ( materialized = MaterializationTypes . table , description = \"Health data exported by the Apple Health App\" , ) id : int = Field ( primary_key = True ) type : str sourceName : str sourceVersion : str unit : str creationDate : datetime startDate : datetime endDate : datetime value : float device : str Source models are models managed outside the scope of Amora, without a source implementation and no dependencies . Model configurations such as materialization type and description are optional, and used for documentation purposes only. Materialized models \u00b6 from amora.compilation import Compilable from amora.models import AmoraModel , MaterializationTypes , ModelConfig from examples.amora_project.models.steps import Steps from sqlmodel import func , select , Field class StepsAgg ( AmoraModel , table = True ): __depends_on__ = [ Steps ] __tablename__ = \"steps_agg\" __model_config__ = ModelConfig ( materialized = MaterializationTypes . table ) avg : float sum : float count : float year : int = Field ( primary_key = True ) month : int = Field ( primary_key = True ) @classmethod def source ( cls ) -> Compilable : sub = select ( [ func . avg ( Steps . value ) . label ( \"avg\" ), func . sum ( Steps . value ) . label ( \"sum\" ), func . count ( Steps . value ) . label ( \"count\" ), func . extract ( \"year\" , Steps . creationDate ) . label ( \"year\" ), func . extract ( \"month\" , Steps . creationDate ) . label ( \"month\" ), ] ) . group_by ( func . extract ( \"year\" , Steps . creationDate ), func . extract ( \"month\" , Steps . creationDate ), ) return sub To-do","title":"Amora Model"},{"location":"models/#amora-model","text":"An Amora Model is a subclass of amora.models.AmoraModel . A way of expressing a data schema , the data materialization and an optional transformation statement. AmoraModel is built on top of SQLModel .","title":"Amora Model"},{"location":"models/#data-schema","text":"from datetime import datetime from amora.models import AmoraModel , ModelConfig , MaterializationTypes from sqlmodel import Field class Health ( AmoraModel , table = True ): __model_config__ = ModelConfig ( materialized = MaterializationTypes . table , description = \"Health data exported by the Apple Health App\" , ) id : int = Field ( primary_key = True ) type : str sourceName : str sourceVersion : str unit : str creationDate : datetime startDate : datetime endDate : datetime value : float device : str","title":"Data schema"},{"location":"models/#model-configuration","text":"Model configuration metadata Attributes: Name Type Description materialized amora.models.MaterializationTypes The materialization configuration: view , table , ephemeral . Default: view partition_by Optional[PartitionConfig] BigQuery supports the use of a partition by clause to easily partition a table by a column or expression. This option can help decrease latency and cost when querying large tables. cluster_by List[str] BigQuery tables can be clustered to colocate related data. Expects a column of a list of columns. labels Dict[str,str] A dict of labels that can be used as the resource selection description int A string description of the model, used for documentation","title":"Model Configuration"},{"location":"models/#transformation","text":"Data transformation is defined at the model source() -> Compilable classmethod. Called when amora compile is executed, Amora will build this model in your data warehouse by wrapping it in a create view as or create table as statement. Return None for defining models for tables/views that already exist on the data warehouse and shouldn't be managed by Amora. Return a Compilable , which is a sqlalchemy select statement, in order to compile the model with the given statement :return: Source code in amora/models.py @classmethod def source ( cls ) -> Optional [ Compilable ]: \"\"\" Called when `amora compile` is executed, Amora will build this model in your data warehouse by wrapping it in a `create view as` or `create table as` statement. Return `None` for defining models for tables/views that already exist on the data warehouse and shouldn't be managed by Amora. Return a `Compilable`, which is a sqlalchemy select statement, in order to compile the model with the given statement :return: \"\"\" return None","title":"Transformation"},{"location":"models/#dependencies","text":"A list of Amora Models that the current model depends on","title":"Dependencies"},{"location":"models/#source-models","text":"Tables/views that already exist on the Data Warehouse and shouldn't be managed by Amora. from datetime import datetime from amora.models import AmoraModel , ModelConfig , MaterializationTypes from sqlmodel import Field class Health ( AmoraModel , table = True ): __model_config__ = ModelConfig ( materialized = MaterializationTypes . table , description = \"Health data exported by the Apple Health App\" , ) id : int = Field ( primary_key = True ) type : str sourceName : str sourceVersion : str unit : str creationDate : datetime startDate : datetime endDate : datetime value : float device : str Source models are models managed outside the scope of Amora, without a source implementation and no dependencies . Model configurations such as materialization type and description are optional, and used for documentation purposes only.","title":"Source models"},{"location":"models/#materialized-models","text":"from amora.compilation import Compilable from amora.models import AmoraModel , MaterializationTypes , ModelConfig from examples.amora_project.models.steps import Steps from sqlmodel import func , select , Field class StepsAgg ( AmoraModel , table = True ): __depends_on__ = [ Steps ] __tablename__ = \"steps_agg\" __model_config__ = ModelConfig ( materialized = MaterializationTypes . table ) avg : float sum : float count : float year : int = Field ( primary_key = True ) month : int = Field ( primary_key = True ) @classmethod def source ( cls ) -> Compilable : sub = select ( [ func . avg ( Steps . value ) . label ( \"avg\" ), func . sum ( Steps . value ) . label ( \"sum\" ), func . count ( Steps . value ) . label ( \"count\" ), func . extract ( \"year\" , Steps . creationDate ) . label ( \"year\" ), func . extract ( \"month\" , Steps . creationDate ) . label ( \"month\" ), ] ) . group_by ( func . extract ( \"year\" , Steps . creationDate ), func . extract ( \"month\" , Steps . creationDate ), ) return sub To-do","title":"Materialized models"},{"location":"tests/assertions/","text":"Data Assertions \u00b6 are_unique_together ( columns : Iterable [ sqlalchemy . orm . attributes . InstrumentedAttribute ]) -> Union [ sqlalchemy . sql . selectable . Select , sqlalchemy . sql . selectable . Selectable ] \u00b6 This test confirms that the combination of columns is unique. For example, the combination of month and product is unique, however neither column is unique in isolation. Source code in amora/tests/assertions.py def are_unique_together ( columns : Iterable [ Column ]) -> Compilable : \"\"\" This test confirms that the combination of columns is unique. For example, the combination of month and product is unique, however neither column is unique in isolation. \"\"\" return ( select ( columns ) . group_by ( * columns ) . having ( func . count ( type_ = Integer ) > 1 ) ) equality ( model_a : AmoraModel , model_b : AmoraModel , compare_columns : Optional [ Iterable [ sqlalchemy . orm . attributes . InstrumentedAttribute ]] = None ) -> bool \u00b6 This schema test asserts the equality of two models. Optionally specify a subset of columns to compare. Source code in amora/tests/assertions.py def equality ( model_a : AmoraModel , model_b : AmoraModel , compare_columns : Optional [ Iterable [ Column ]] = None , ) -> bool : \"\"\" This schema test asserts the equality of two models. Optionally specify a subset of columns to compare. \"\"\" raise NotImplementedError def comparable_columns ( model : AmoraModel ) -> Iterable [ Column ]: if not compare_columns : return model return [ getattr ( model , column_name ) for column_name in compare_columns ] a = select ( comparable_columns ( model_a )) . cte ( \"a\" ) b = select ( comparable_columns ( model_b )) . cte ( \"b\" ) # fixme: google.api_core.exceptions.BadRequest: 400 EXCEPT must be followed by ALL, DISTINCT, or \"(\" at [34:4] a_minus_b = select ( a ) . except_ ( select ( b )) b_minus_a = select ( b ) . except_ ( select ( a )) diff_union = union_all ( a_minus_b , b_minus_a ) return _test ( statement = diff_union ) expression_is_true ( expression , condition = < sqlalchemy . sql . elements . AsBoolean object at 0x1276517f0 > ) -> bool \u00b6 expression_is_true(StepsAgg._sum > StepsAgg._avg, condition=StepsAgg.year == 2021) Asserts that a expression is TRUE for all records. This is useful when checking integrity across columns, for example, that a total is equal to the sum of its parts, or that at least one column is true. Optionally assert expression only for rows where condition is met. ``` Source code in amora/tests/assertions.py def expression_is_true ( expression , condition = and_ ( True )) -> bool : \"\"\" >>> expression_is_true(StepsAgg._sum > StepsAgg._avg, condition=StepsAgg.year == 2021) Asserts that a expression is TRUE for all records. This is useful when checking integrity across columns, for example, that a total is equal to the sum of its parts, or that at least one column is true. Optionally assert `expression` only for rows where `condition` is met. ``` \"\"\" return _test ( statement = select ([ \"*\" ]) . where ( condition ) . where ( ~ expression )) has_accepted_values ( column : InstrumentedAttribute , values : Iterable ) -> Union [ sqlalchemy . sql . selectable . Select , sqlalchemy . sql . selectable . Selectable ] \u00b6 has_accepted_values(HeartRate.source, values=[\"iPhone\", \"Mi Band\"]) The source column in the HeartRate model should be one of 'iPhone' or 'MiBand' SELECT {{ column_name }} FROM {{ model }} WHERE {{ column_name }} NOT IN {{ values }} Source code in amora/tests/assertions.py def has_accepted_values ( column : Column , values : Iterable ) -> Compilable : \"\"\" >>> has_accepted_values(HeartRate.source, values=[\"iPhone\", \"Mi Band\"]) The `source` column in the `HeartRate` model should be one of 'iPhone' or 'MiBand' ```sql SELECT {{ column_name }} FROM {{ model }} WHERE {{ column_name }} NOT IN {{ values }} ``` \"\"\" return select ( column ) . where ( ~ column . in_ ( values )) has_at_least_one_not_null_value ( column : InstrumentedAttribute ) -> Union [ sqlalchemy . sql . selectable . Select , sqlalchemy . sql . selectable . Selectable ] \u00b6 Asserts if column has at least one value. SELECT count ( {{ column_name }} ) as filler_column FROM {{ model }} HAVING count ( {{ column_name }} ) = 0 Source code in amora/tests/assertions.py def has_at_least_one_not_null_value ( column : Column ) -> Compilable : \"\"\" Asserts if column has at least one value. ```sql SELECT count({{ column_name }}) as filler_column FROM {{ model }} HAVING count({{ column_name }}) = 0 ``` \"\"\" return select ( func . count ( column , type_ = Integer )) . having ( func . count ( column ) == 0 ) is_non_negative ( column : InstrumentedAttribute ) -> Union [ sqlalchemy . sql . selectable . Select , sqlalchemy . sql . selectable . Selectable ] \u00b6 is_non_negative(HeartRate.value) True Each not null value in HeartRate model is >= 0 SELECT {{ column_name }} FROM {{ model }} WHERE {{ column_name }} < 0 Source code in amora/tests/assertions.py def is_non_negative ( column : Column ) -> Compilable : \"\"\" >>> is_non_negative(HeartRate.value) True Each not null `value` in `HeartRate` model is >= 0 ```sql SELECT {{ column_name }} FROM {{ model }} WHERE {{ column_name }} < 0 ``` \"\"\" return select ( column ) . where ( column < 0 ) is_not_null ( column : InstrumentedAttribute ) -> Union [ sqlalchemy . sql . selectable . Select , sqlalchemy . sql . selectable . Selectable ] \u00b6 is_not_null(HeartRate.id) The id column in the HeartRate model should not contain null values Results in the following query: SELECT {{ column_name }} FROM {{ model }} WHERE {{ column_name }} IS NULL Source code in amora/tests/assertions.py def is_not_null ( column : Column ) -> Compilable : \"\"\" >>> is_not_null(HeartRate.id) The `id` column in the `HeartRate` model should not contain `null` values Results in the following query: ```sql SELECT {{ column_name }} FROM {{ model }} WHERE {{ column_name }} IS NULL ``` \"\"\" return select ( column ) . where ( column == None ) is_numeric ( column : InstrumentedAttribute ) -> Union [ sqlalchemy . sql . selectable . Select , sqlalchemy . sql . selectable . Selectable ] \u00b6 is_numeric(func.cast(Health.value, String).label('value_as_str')) True Asserts that each not null value is a number WITH ` int_col_or_null ` AS ( SELECT CAST ( {{ column }} , INT64 ) AS ` col ` FROM {{ model }} WHERE {{ column }} IS NOT NULL ) SELECT col FROM int_col_or_null WHERE col IS NULL Source code in amora/tests/assertions.py def is_numeric ( column : Column ) -> Compilable : \"\"\" >>> is_numeric(func.cast(Health.value, String).label('value_as_str')) True Asserts that each not null value is a number ```sql WITH `int_col_or_null` AS ( SELECT CAST({{ column }}, INT64) AS `col` FROM {{ model }} WHERE {{ column }} IS NOT NULL ) SELECT col FROM int_col_or_null WHERE col IS NULL ``` \"\"\" int_col_or_null = ( select ( func . cast ( column , Integer ) . label ( \"col\" )) . where ( column != None ) . cte ( \"int_col_or_null\" ) ) return select ( int_col_or_null . c . col ) . where ( int_col_or_null . c . col == None ) is_unique ( column : InstrumentedAttribute ) -> Union [ sqlalchemy . sql . selectable . Select , sqlalchemy . sql . selectable . Selectable ] \u00b6 is_unique(HeartRate.id) The id column in the HeartRate model should be unique SELECT {{ column_name }} FROM ( SELECT {{ column_name }} FROM {{ model }} WHERE {{ column_name }} IS NOT NULL GROUP BY {{ column_name }} HAVING COUNT ( * ) > 1 ) validation_errors Source code in amora/tests/assertions.py def is_unique ( column : Column ) -> Compilable : \"\"\" >>> is_unique(HeartRate.id) The `id` column in the `HeartRate` model should be unique ```sql SELECT {{ column_name }} FROM ( SELECT {{ column_name }} FROM {{ model }} WHERE {{ column_name }} IS NOT NULL GROUP BY {{ column_name }} HAVING COUNT(*) > 1 ) validation_errors ``` \"\"\" return select ( column ) . group_by ( column ) . having ( func . count ( column ) > 1 ) relationship ( from_ : InstrumentedAttribute , to : InstrumentedAttribute , from_condition = < sqlalchemy . sql . elements . AsBoolean object at 0x127651820 > , to_condition = < sqlalchemy . sql . elements . AsBoolean object at 0x1276517c0 > ) -> bool \u00b6 relationship(HeartRate.id, to=Health.id) Each id in the HeartRate model exists as an id in the Health table (also known as referential integrity) This test validates the referential integrity between two relations with a predicate ( from_condition and to_condition ) to filter out some rows from the test. This is useful to exclude records such as test entities, rows created in the last X minutes/hours to account for temporary gaps due to data ingestion limitations, etc. WITH left_table AS ( SELECT {{ from_column_name }} AS id FROM {{ from_table }} WHERE {{ from_column_name }} IS NOT NULL AND {{ from_condition }} ), right_table AS ( SELECT {{ to_column_name }} AS id FROM {{ to_table }} WHERE {{ to_column_name }} IS NOT NULL AND {{ to_condition }} ), exceptions as ( SELECT left_table . id AS {{ from_column_name }}} FROM left_table LEFT JOIN right_table ON left_table . id = right_table . id WHERE right_table . id IS NULL ) SELECT * FROM exceptions Source code in amora/tests/assertions.py def relationship ( from_ : Column , to : Column , from_condition = and_ ( True ), to_condition = and_ ( True ), ) -> bool : \"\"\" >>> relationship(HeartRate.id, to=Health.id) Each `id` in the `HeartRate` model exists as an `id` in the `Health` table (also known as referential integrity) This test validates the referential integrity between two relations with a predicate (`from_condition` and `to_condition`) to filter out some rows from the test. This is useful to exclude records such as test entities, rows created in the last X minutes/hours to account for temporary gaps due to data ingestion limitations, etc. ```sql WITH left_table AS ( SELECT {{from_column_name}} AS id FROM {{from_table}} WHERE {{from_column_name}} IS NOT NULL AND {{from_condition}} ), right_table AS ( SELECT {{to_column_name}} AS id FROM {{to_table}} WHERE {{to_column_name}} IS NOT NULL AND {{to_condition}} ), exceptions as ( SELECT left_table.id AS {{from_column_name}}} FROM left_table LEFT JOIN right_table ON left_table.id = right_table.id WHERE right_table.id IS NULL ) SELECT * FROM exceptions ``` \"\"\" left_table = ( select ( from_ . label ( \"id\" )) . where ( from_ != None ) . where ( from_condition ) . cte ( \"left_table\" ) ) right_table = ( select ( to . label ( \"id\" )) . where ( to != None ) . where ( to_condition ) . cte ( \"right_table\" ) ) exceptions = ( select ([ left_table . c [ \"id\" ] . label ( from_ . key )]) . select_from ( left_table . join ( right_table , onclause = left_table . c [ \"id\" ] == right_table . c [ \"id\" ], isouter = True , ) ) . where ( right_table . c [ \"id\" ] == None ) ) return _test ( statement = exceptions ) that ( column : InstrumentedAttribute , test : Callable [ ... , sqlmodel . sql . expression . SelectOfScalar ], ** test_kwargs ) -> bool \u00b6 assert that(HeartRate.value, is_not_null) Executes the test, returning True if the test is successful and raising a pytest fail otherwise Source code in amora/tests/assertions.py def that ( column : Column , test : Test , ** test_kwargs , ) -> bool : \"\"\" >>> assert that(HeartRate.value, is_not_null) Executes the test, returning True if the test is successful and raising a pytest fail otherwise \"\"\" return _test ( statement = test ( column , ** test_kwargs ))","title":"Data Assertions"},{"location":"tests/assertions/#data-assertions","text":"","title":"Data Assertions"},{"location":"tests/assertions/#amora.tests.assertions.are_unique_together","text":"This test confirms that the combination of columns is unique. For example, the combination of month and product is unique, however neither column is unique in isolation. Source code in amora/tests/assertions.py def are_unique_together ( columns : Iterable [ Column ]) -> Compilable : \"\"\" This test confirms that the combination of columns is unique. For example, the combination of month and product is unique, however neither column is unique in isolation. \"\"\" return ( select ( columns ) . group_by ( * columns ) . having ( func . count ( type_ = Integer ) > 1 ) )","title":"are_unique_together()"},{"location":"tests/assertions/#amora.tests.assertions.equality","text":"This schema test asserts the equality of two models. Optionally specify a subset of columns to compare. Source code in amora/tests/assertions.py def equality ( model_a : AmoraModel , model_b : AmoraModel , compare_columns : Optional [ Iterable [ Column ]] = None , ) -> bool : \"\"\" This schema test asserts the equality of two models. Optionally specify a subset of columns to compare. \"\"\" raise NotImplementedError def comparable_columns ( model : AmoraModel ) -> Iterable [ Column ]: if not compare_columns : return model return [ getattr ( model , column_name ) for column_name in compare_columns ] a = select ( comparable_columns ( model_a )) . cte ( \"a\" ) b = select ( comparable_columns ( model_b )) . cte ( \"b\" ) # fixme: google.api_core.exceptions.BadRequest: 400 EXCEPT must be followed by ALL, DISTINCT, or \"(\" at [34:4] a_minus_b = select ( a ) . except_ ( select ( b )) b_minus_a = select ( b ) . except_ ( select ( a )) diff_union = union_all ( a_minus_b , b_minus_a ) return _test ( statement = diff_union )","title":"equality()"},{"location":"tests/assertions/#amora.tests.assertions.expression_is_true","text":"expression_is_true(StepsAgg._sum > StepsAgg._avg, condition=StepsAgg.year == 2021) Asserts that a expression is TRUE for all records. This is useful when checking integrity across columns, for example, that a total is equal to the sum of its parts, or that at least one column is true. Optionally assert expression only for rows where condition is met. ``` Source code in amora/tests/assertions.py def expression_is_true ( expression , condition = and_ ( True )) -> bool : \"\"\" >>> expression_is_true(StepsAgg._sum > StepsAgg._avg, condition=StepsAgg.year == 2021) Asserts that a expression is TRUE for all records. This is useful when checking integrity across columns, for example, that a total is equal to the sum of its parts, or that at least one column is true. Optionally assert `expression` only for rows where `condition` is met. ``` \"\"\" return _test ( statement = select ([ \"*\" ]) . where ( condition ) . where ( ~ expression ))","title":"expression_is_true()"},{"location":"tests/assertions/#amora.tests.assertions.has_accepted_values","text":"has_accepted_values(HeartRate.source, values=[\"iPhone\", \"Mi Band\"]) The source column in the HeartRate model should be one of 'iPhone' or 'MiBand' SELECT {{ column_name }} FROM {{ model }} WHERE {{ column_name }} NOT IN {{ values }} Source code in amora/tests/assertions.py def has_accepted_values ( column : Column , values : Iterable ) -> Compilable : \"\"\" >>> has_accepted_values(HeartRate.source, values=[\"iPhone\", \"Mi Band\"]) The `source` column in the `HeartRate` model should be one of 'iPhone' or 'MiBand' ```sql SELECT {{ column_name }} FROM {{ model }} WHERE {{ column_name }} NOT IN {{ values }} ``` \"\"\" return select ( column ) . where ( ~ column . in_ ( values ))","title":"has_accepted_values()"},{"location":"tests/assertions/#amora.tests.assertions.has_at_least_one_not_null_value","text":"Asserts if column has at least one value. SELECT count ( {{ column_name }} ) as filler_column FROM {{ model }} HAVING count ( {{ column_name }} ) = 0 Source code in amora/tests/assertions.py def has_at_least_one_not_null_value ( column : Column ) -> Compilable : \"\"\" Asserts if column has at least one value. ```sql SELECT count({{ column_name }}) as filler_column FROM {{ model }} HAVING count({{ column_name }}) = 0 ``` \"\"\" return select ( func . count ( column , type_ = Integer )) . having ( func . count ( column ) == 0 )","title":"has_at_least_one_not_null_value()"},{"location":"tests/assertions/#amora.tests.assertions.is_non_negative","text":"is_non_negative(HeartRate.value) True Each not null value in HeartRate model is >= 0 SELECT {{ column_name }} FROM {{ model }} WHERE {{ column_name }} < 0 Source code in amora/tests/assertions.py def is_non_negative ( column : Column ) -> Compilable : \"\"\" >>> is_non_negative(HeartRate.value) True Each not null `value` in `HeartRate` model is >= 0 ```sql SELECT {{ column_name }} FROM {{ model }} WHERE {{ column_name }} < 0 ``` \"\"\" return select ( column ) . where ( column < 0 )","title":"is_non_negative()"},{"location":"tests/assertions/#amora.tests.assertions.is_not_null","text":"is_not_null(HeartRate.id) The id column in the HeartRate model should not contain null values Results in the following query: SELECT {{ column_name }} FROM {{ model }} WHERE {{ column_name }} IS NULL Source code in amora/tests/assertions.py def is_not_null ( column : Column ) -> Compilable : \"\"\" >>> is_not_null(HeartRate.id) The `id` column in the `HeartRate` model should not contain `null` values Results in the following query: ```sql SELECT {{ column_name }} FROM {{ model }} WHERE {{ column_name }} IS NULL ``` \"\"\" return select ( column ) . where ( column == None )","title":"is_not_null()"},{"location":"tests/assertions/#amora.tests.assertions.is_numeric","text":"is_numeric(func.cast(Health.value, String).label('value_as_str')) True Asserts that each not null value is a number WITH ` int_col_or_null ` AS ( SELECT CAST ( {{ column }} , INT64 ) AS ` col ` FROM {{ model }} WHERE {{ column }} IS NOT NULL ) SELECT col FROM int_col_or_null WHERE col IS NULL Source code in amora/tests/assertions.py def is_numeric ( column : Column ) -> Compilable : \"\"\" >>> is_numeric(func.cast(Health.value, String).label('value_as_str')) True Asserts that each not null value is a number ```sql WITH `int_col_or_null` AS ( SELECT CAST({{ column }}, INT64) AS `col` FROM {{ model }} WHERE {{ column }} IS NOT NULL ) SELECT col FROM int_col_or_null WHERE col IS NULL ``` \"\"\" int_col_or_null = ( select ( func . cast ( column , Integer ) . label ( \"col\" )) . where ( column != None ) . cte ( \"int_col_or_null\" ) ) return select ( int_col_or_null . c . col ) . where ( int_col_or_null . c . col == None )","title":"is_numeric()"},{"location":"tests/assertions/#amora.tests.assertions.is_unique","text":"is_unique(HeartRate.id) The id column in the HeartRate model should be unique SELECT {{ column_name }} FROM ( SELECT {{ column_name }} FROM {{ model }} WHERE {{ column_name }} IS NOT NULL GROUP BY {{ column_name }} HAVING COUNT ( * ) > 1 ) validation_errors Source code in amora/tests/assertions.py def is_unique ( column : Column ) -> Compilable : \"\"\" >>> is_unique(HeartRate.id) The `id` column in the `HeartRate` model should be unique ```sql SELECT {{ column_name }} FROM ( SELECT {{ column_name }} FROM {{ model }} WHERE {{ column_name }} IS NOT NULL GROUP BY {{ column_name }} HAVING COUNT(*) > 1 ) validation_errors ``` \"\"\" return select ( column ) . group_by ( column ) . having ( func . count ( column ) > 1 )","title":"is_unique()"},{"location":"tests/assertions/#amora.tests.assertions.relationship","text":"relationship(HeartRate.id, to=Health.id) Each id in the HeartRate model exists as an id in the Health table (also known as referential integrity) This test validates the referential integrity between two relations with a predicate ( from_condition and to_condition ) to filter out some rows from the test. This is useful to exclude records such as test entities, rows created in the last X minutes/hours to account for temporary gaps due to data ingestion limitations, etc. WITH left_table AS ( SELECT {{ from_column_name }} AS id FROM {{ from_table }} WHERE {{ from_column_name }} IS NOT NULL AND {{ from_condition }} ), right_table AS ( SELECT {{ to_column_name }} AS id FROM {{ to_table }} WHERE {{ to_column_name }} IS NOT NULL AND {{ to_condition }} ), exceptions as ( SELECT left_table . id AS {{ from_column_name }}} FROM left_table LEFT JOIN right_table ON left_table . id = right_table . id WHERE right_table . id IS NULL ) SELECT * FROM exceptions Source code in amora/tests/assertions.py def relationship ( from_ : Column , to : Column , from_condition = and_ ( True ), to_condition = and_ ( True ), ) -> bool : \"\"\" >>> relationship(HeartRate.id, to=Health.id) Each `id` in the `HeartRate` model exists as an `id` in the `Health` table (also known as referential integrity) This test validates the referential integrity between two relations with a predicate (`from_condition` and `to_condition`) to filter out some rows from the test. This is useful to exclude records such as test entities, rows created in the last X minutes/hours to account for temporary gaps due to data ingestion limitations, etc. ```sql WITH left_table AS ( SELECT {{from_column_name}} AS id FROM {{from_table}} WHERE {{from_column_name}} IS NOT NULL AND {{from_condition}} ), right_table AS ( SELECT {{to_column_name}} AS id FROM {{to_table}} WHERE {{to_column_name}} IS NOT NULL AND {{to_condition}} ), exceptions as ( SELECT left_table.id AS {{from_column_name}}} FROM left_table LEFT JOIN right_table ON left_table.id = right_table.id WHERE right_table.id IS NULL ) SELECT * FROM exceptions ``` \"\"\" left_table = ( select ( from_ . label ( \"id\" )) . where ( from_ != None ) . where ( from_condition ) . cte ( \"left_table\" ) ) right_table = ( select ( to . label ( \"id\" )) . where ( to != None ) . where ( to_condition ) . cte ( \"right_table\" ) ) exceptions = ( select ([ left_table . c [ \"id\" ] . label ( from_ . key )]) . select_from ( left_table . join ( right_table , onclause = left_table . c [ \"id\" ] == right_table . c [ \"id\" ], isouter = True , ) ) . where ( right_table . c [ \"id\" ] == None ) ) return _test ( statement = exceptions )","title":"relationship()"},{"location":"tests/assertions/#amora.tests.assertions.that","text":"assert that(HeartRate.value, is_not_null) Executes the test, returning True if the test is successful and raising a pytest fail otherwise Source code in amora/tests/assertions.py def that ( column : Column , test : Test , ** test_kwargs , ) -> bool : \"\"\" >>> assert that(HeartRate.value, is_not_null) Executes the test, returning True if the test is successful and raising a pytest fail otherwise \"\"\" return _test ( statement = test ( column , ** test_kwargs ))","title":"that()"}]}